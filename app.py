import streamlit as st
from google import genai
from google.genai import types
import pandas as pd
import io
from datetime import datetime
import time

# --- Configuration and Initialization ---
APP_TITLE = "ğŸ‘• Streamlit ê¸°ë°˜ ì˜ìƒ ì¶”ì²œ AI ì±—ë´‡"
DEFAULT_MODEL = "gemini-2.0-flash"
SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ê³ ê°ì˜ ìƒí™©ì— ë§ëŠ” ì˜·ì°¨ë¦¼ì„ ê°„ê²°í•˜ê²Œ ì¶”ì²œí•´ì£¼ëŠ” ì¹œì ˆí•œ AI ìŠ¤íƒ€ì¼ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
ê³ ê°ì€ ì™¸ì¶œ ì „ ë°”ìœ ìƒí™©ì´ë¯€ë¡œ, ëŒ€ë‹µì€ ë°˜ë“œì‹œ ê°„ê²°í•˜ê³  ì‹¤ìš©ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤.

[ìš´ì˜ ê·œì¹™]
1. ì‚¬ìš©ìê°€ ì˜¤ëŠ˜ì˜ ì˜¨ë„, ì¼êµì°¨, ì–´ë–¤ í™œë™ì„ í•˜ëŠ”ì§€, ì„±ë³„, ë‚˜ì´ ë“±ì˜ ì •ë³´ë¥¼ ì œê³µí•˜ë©´, ì´ ì •ë³´ë¥¼ **êµ¬ì²´ì ìœ¼ë¡œ** ì •ë¦¬í•˜ì—¬ ìˆ˜ì§‘í•˜ì„¸ìš”.
2. ì •ë³´ê°€ ì¶©ë¶„í•˜ì§€ ì•Šìœ¼ë©´, ë¶€ì¡±í•œ ë¶€ë¶„ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ **ê°„ê²°í•˜ê²Œ** ë˜ë¬¼ì–´ë³´ì„¸ìš”.
3. í•„ìš”í•œ ì •ë³´ë¥¼ ëª¨ë‘ ìˆ˜ì§‘í•œ í›„ì—ëŠ”, ì‚¬ìš©ìì˜ ìƒí™©(ì˜¨ë„/í™œë™/ì„±ë³„/ë‚˜ì´ ë“±)ì— ë§ëŠ” **ì‹¤ìš©ì ì¸ ì˜·ì°¨ë¦¼**ì„ í•œ ë¬¸ë‹¨ìœ¼ë¡œ **ê°„ê²°í•˜ê²Œ** ì¶”ì²œí•˜ì„¸ìš”.
4. ë§ˆì§€ë§‰ì—ëŠ” ë°˜ë“œì‹œ ë‹¤ìŒ ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•˜ì„¸ìš”: "ì˜¤ëŠ˜ì˜ ë‹¹ì‹ ì—ê²Œ ë§ëŠ” ìƒí’ˆì„ ì¶”ì²œí•´ë“œë¦´ ìˆ˜ ìˆì–´ìš”."ë¼ê³  ì •ì¤‘íˆ ì•ˆë‚´í•˜ì„¸ìš”.
"""
RESTART_MESSAGE = "â—ï¸ API ìš”ì²­ ì˜¤ë¥˜(429 ë“±)ê°€ ë°œìƒí•˜ì—¬ ì´ì „ 6í„´ì˜ ëŒ€í™”ë§Œ ìœ ì§€í•˜ê³  ì±„íŒ… ì„¸ì…˜ì„ ì¬ì‹œì‘í•©ë‹ˆë‹¤."
MAX_HISTORY_TURN = 6 # Max turns (user/model pair) to keep upon 429 restart

# Available models list (excluding -exp)
AVAILABLE_MODELS = [
    "gemini-2.0-flash",
    "gemini-2.5-flash",
    "gemini-2.0-pro",
    "gemini-2.5-pro",
]

st.set_page_config(page_title=APP_TITLE, layout="wide")
st.title(APP_TITLE)

# --- State Initialization Helpers ---

def get_api_key():
    """Load API key from st.secrets or prompt user input."""
    api_key = st.secrets.get('GEMINI_API_KEY')
    if not api_key:
        api_key = st.sidebar.text_input("Gemini API Key", type="password", help="Streamlit Secretsì— ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš° ì—¬ê¸°ì— ì…ë ¥í•˜ì„¸ìš”.")
        
    if not api_key:
        st.info("ì™¼ìª½ ì‚¬ì´ë“œë°”ì— Gemini API í‚¤ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ Streamlit Secretsì— ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.")
        st.stop()
        
    return api_key

def initialize_client_and_chat(api_key, model_name, system_prompt, history_to_restore=None):
    """Initializes Gemini client and a new Chat session."""
    try:
        client = genai.Client(api_key=api_key)
        
        # System instruction configuration
        config = types.GenerateContentConfig(
            system_instruction=system_prompt
        )
        
        # Start new Chat session
        chat = client.chats.create(model=model_name, config=config)
        st.session_state.gemini_chat = chat
        st.session_state.model_name = model_name
        
        # Restore history if provided (used for 429 restart)
        if history_to_restore:
            # Reconstruct Chat history for the new session
            for msg in history_to_restore:
                # Map Streamlit role to Gemini role
                role_map = {"user": "user", "assistant": "model"}
                chat.history.append(
                    types.Content(
                        role=role_map[msg["role"]],
                        parts=[types.Part.from_text(msg["content"])]
                    )
                )
            st.session_state.messages = history_to_restore
            st.session_state.messages.append({"role": "assistant", "content": RESTART_MESSAGE})
            st.session_state.history_log.append({
                "Timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                "Role": "assistant",
                "Content": RESTART_MESSAGE,
                "Model": st.session_state.model_name
            })
            
        else:
            st.session_state.messages = []
            st.session_state.history_log = [] # Full conversation log for CSV
            
        st.rerun()
        
    except Exception as e:
        st.error(f"Gemini í´ë¼ì´ì–¸íŠ¸/ì±„íŒ… ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
        st.stop()


# 3. Initial session setup if not exists
if 'gemini_chat' not in st.session_state:
    st.session_state.messages = []
    st.session_state.history_log = []
    st.session_state.model_name = DEFAULT_MODEL
    
# --- Sidebar and UI Configuration ---

with st.sidebar:
    st.header("ì„¤ì • ë° ë„êµ¬")
    
    # Model Selection
    selected_model = st.selectbox(
        "ì‚¬ìš©í•  ëª¨ë¸ ì„ íƒ", 
        AVAILABLE_MODELS,
        index=AVAILABLE_MODELS.index(DEFAULT_MODEL),
        key="model_select_key"
    )
    
    # API Key Load (Stops if not available)
    api_key = get_api_key()
    
    # Session Reset Button
    if st.button("ğŸ’¬ ëŒ€í™” ì´ˆê¸°í™” ë° ëª¨ë¸ ì ìš©", help="ëŒ€í™” ê¸°ë¡ì„ ì§€ìš°ê³  ìƒˆ ëª¨ë¸ë¡œ ì‹œì‘í•©ë‹ˆë‹¤."):
        initialize_client_and_chat(api_key, selected_model, SYSTEM_PROMPT)

    st.markdown("---")
    st.subheader("ë¡œê·¸ ê¸°ë¡ ì˜µì…˜")
    
    # CSV Logging Option
    if 'auto_log' not in st.session_state:
        st.session_state.auto_log = False
    st.session_state.auto_log = st.checkbox("CSV ìë™ ê¸°ë¡ (ëŒ€í™”ë§ˆë‹¤ ê¸°ë¡)", st.session_state.auto_log)
    
    # Log Download
    if st.session_state.history_log:
        log_df = pd.DataFrame(st.session_state.history_log)
        # Convert to CSV and ensure proper encoding
        csv_data = log_df.to_csv(index=False).encode('utf-8')
        st.download_button(
            label="â¬‡ï¸ ëŒ€í™” ë¡œê·¸ CSV ë‹¤ìš´ë¡œë“œ",
            data=csv_data,
            file_name=f"gemini_chat_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv",
        )
    else:
        st.info("ë¡œê·¸ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")

# Client and Chat session check (Re-initialize if model changed or first run)
if 'gemini_chat' not in st.session_state or st.session_state.model_name != selected_model:
    if api_key:
        initialize_client_and_chat(api_key, selected_model, SYSTEM_PROMPT)

# Display Model and Session Info
st.sidebar.markdown("---")
st.sidebar.markdown(f"**í˜„ì¬ ëª¨ë¸:** `{st.session_state.model_name}`")
st.sidebar.markdown(f"**ì´ í„´ ìˆ˜:** {len(st.session_state.messages)//2} (ë©”ì‹œì§€ {len(st.session_state.messages)}ê°œ)")


# --- Display Conversation History ---
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- User Input Processing ---
if prompt := st.chat_input("ì˜¤ëŠ˜ì˜ ë‚ ì”¨ì™€ ì¼ì •ì„ ë§ì”€í•´ ì£¼ì„¸ìš” (ì˜ˆ: ì˜¤ëŠ˜ ìµœê³  25ë„, ìµœì € 10ë„, ì¹œêµ¬ì™€ ì¹´í˜ì— ê°‘ë‹ˆë‹¤, ì—¬ì„±, 30ëŒ€)"):
    # 1. Record and Display User Message
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # Log User Message
    st.session_state.history_log.append({
        "Timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        "Role": "user",
        "Content": prompt,
        "Model": st.session_state.model_name
    })
    
    with st.chat_message("user"):
        st.markdown(prompt)

    # 2. Call Gemini API
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""
        
        try:
            # Use send_message for continuous conversation
            response = st.session_state.gemini_chat.send_message(prompt, stream=True)
            
            # Stream the response
            for chunk in response:
                if chunk.text:
                    full_response += chunk.text
                    message_placeholder.markdown(full_response + "â–Œ")
            
            message_placeholder.markdown(full_response)
        
        except types.errors.ResourceExhaustedError: # Handle 429
            # Get the last MAX_HISTORY_TURN pairs
            history_to_keep = st.session_state.messages[-(MAX_HISTORY_TURN * 2):]
            log_to_keep = st.session_state.history_log[-(MAX_HISTORY_TURN * 2):]

            # Re-initialize client/chat, restoring history
            initialize_client_and_chat(api_key, st.session_state.model_name, SYSTEM_PROMPT, history_to_keep)
            # Rerun will happen inside the helper function
            
        except Exception as e:
            full_response = f"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
            message_placeholder.markdown(full_response)
            
        # 3. Record Model Response
        if full_response and full_response != RESTART_MESSAGE:
            st.session_state.messages.append({"role": "assistant", "content": full_response})
            
            # Log Assistant Message (if not a restart message)
            if st.session_state.auto_log:
                st.session_state.history_log.append({
                    "Timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    "Role": "assistant",
                    "Content": full_response,
                    "Model": st.session_state.model_name
                })
        
    st.rerun() # Refresh to show updated chat